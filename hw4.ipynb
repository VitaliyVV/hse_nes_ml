{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "*Екатерина Лобачева / Илья Щуров / Сергей Сметанин *\n",
    "\n",
    "*Совместный бакалавриат НИУ ВШЭ и РЭШ, 2016-17 учебный год*\n",
    "\n",
    "[Страница курса](http://math-info.hse.ru/2016-17/Machine_Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №ML4\n",
    "\n",
    "Это задание основано на *Лабораторной работе №15* курса [Анализ данных (программная инженерия)](http://wiki.cs.hse.ru/%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85_%28%D0%9F%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%BD%D0%B0%D1%8F_%D0%B8%D0%BD%D0%B6%D0%B5%D0%BD%D0%B5%D1%80%D0%B8%D1%8F%29).\n",
    "\n",
    "Чтобы выполнить работу, скачайте настоящий ipynb-файл, откройте его в *Jupyter Notebook*, впишите решения в оставленные для этого ячейки (при необходимости можно добавлять новые ячейки), приводя полный работающий код, а также все необходимые пояснения и ответы (для этого нужно использовать markdown-ячейки). Вы можете вставлять формулы с помощью TeX-разметки в markdown-ячейки. После выполнения работы необходимо вытащить ipynb-файл из Jupyter (например, с помощью *File → Download as… → IPython Notebook*) и загрузить его на my.NES.\n",
    "\n",
    "### PyBrain\n",
    "Для выполнения практической части этого задания (задачи 2) нужно использовать библиотеку [pybrain](http://pybrain.org). Чтобы её установить, нужно скачать исходный коды с [github](https://github.com/pybrain/pybrain) (кнопка *Clone or download*), распаковать, перейти в соответствующий каталог в командной строке и набрать \n",
    "    \n",
    "    python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 1\n",
    "Рассмотрим нейронную сеть с одним скрытым слоем, сигмоидной функцией активации и одним выходным нейроном. Предположим, что мы хотим обучить эту сеть с помощью градиентного спуска и обратного распространения ошибки (backpropagation). При этом в качестве начальной точки градиентного спуска мы взяли точку, в которой все веса равны нулю. Найти, чему может при этом равняться вектор градиента (при какой-нибудь обучающей выборке). Как изменятся веса после первого шага градиентного спуска? Что будет происходить на следующих шагах?\n",
    "\n",
    "Эта задача показывает, почему инциализировать все веса нулями плохо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании вам нужно приблизить функцию $f(x) = x^3$ на отрезке $[-3, 2]$ с помощью нейросети.\n",
    "\n",
    "1. С помощью библиотеки *pybrain* создайте архитектуру нейросети, состоящую из следующих слоев: *входной слой* (`pybrain.structure.LinearLayer`) → *скрытый слой* (`pybrain.structure.TanhLayer`) → *выходной слой* (`pybrain.structure.LinearLayer`). Поскольку мы хотим приблизить функцию, действующую из одномерного пространства в одномерное, входной и выходной слои должны иметь размерность 1. Для создания нейросети можно использовать функцию [`pybrain.tools.shortcuts.buildNetwork`](http://pybrain.org/docs/quickstart/network.html).\n",
    "2. Составьте обучающую выборку  (`pybrain.datasets.SupervisedDataSet`) из $2000$ равномерно распределённых точек на отрезке $[-3 ,2]$, а также две тестовых выборки из $1000$ точек — на том же отрезке и на отрезке $[-3, 3]$.\n",
    "3. Постройте графики зависимости среднеквадратичной ошибки аппроксимации (`pybrain.tools.validation.ModuleValidator.MSE`) на обеих тестовых выборках в зависимости от числа нейронов в скрытом слое (от $1$ до $101$ с шагом $10$). Делайте не менее $100$ эпох при обучении, используйте уменьшение весов (`weightdecay`) с коэффициентом $10^{-5}$.\n",
    "    1. Какого минимального числа нейронов достаточно для аппроксимации функции на данном отрезке?\n",
    "\t2. Прокомментируйте отличие ошибок на двух тестовых выборках\n",
    "\t3. Визуализируйте на одном графике $f(x)$ и аппроксимации с помощью нейросети с числом нейронов в скрытом слое $1, 5, 10, 20, 50, 100, 200$ на отрезке $[-3, 3]$. \n",
    "4. Повторите исследование в пуктах 2-4, используя в качестве обучающей выборки точки из области $[-3, 1] \\cup [2, 3]$. Прокомментируйте разницу в качестве аппроксимации функции на неизвестных участках.\n",
    "\n",
    "**Подсказка**. Вычислять среднеквадратичную ошибку можно так:\n",
    "\n",
    "    from pybrain.tools.validation import ModuleValidator\n",
    "    # ... your code to create and train network\n",
    "    print(ModuleValidator.MSE(trainer.module, dataset_test))\n",
    "    \n",
    "здесь `trainer` — это обученный объект класса `pybrain.supervised.trainers.BackpropTrainer`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": false,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
